챕터4 스레드(Threads)
4.1 개요
4.2 다중 스레드 모델
4.3 스레드 라이브러리
4.4 Java 스레드
4.5 스레드와 관련된 문제들
4.6 운영체제 사례
챕터5 CPU 스케줄링
5.1 기본 개념
5.2 스케줄링 기준
5.3 스케줄링 알고리즘
5.4 다중처리기 스케줄링
5.5 스레드 스케줄링
5.6 운영체제 사례들
5.7 Java 스케줄링 (책 다시읽기!)
5.8 알고리즘의 평가
챕터6 프로세스 동기화
6.1 배경
6.2 임계영역 문제
5.3 피터슨의 해결안
6.4 동기화 하드웨어
6.5 세마포 챕터4 스레드(Threads)
4.1 개요
4.2 다중 스레드 모델

사용자 스레드와 커널 스레드간의 연관관계

사용자 스레드 : 커널 위에서 커널 지원 없이 관리됨
커널 스레드 : OS 의해 직접 지원, 관리

다 - 대 - 일 모델
많은 사용자 수준 스레드를 하나의 커널 스레드로 사상
스레드 관리는 사용자 공간의 스레드 라이브러리가
효율적 but 스레드가 봉쇄형 sys호출시 전체 프로세스 봉쇄
한 스레드만 커널 접근 => 다중 처리기에서도 병렬 작동 x
예시 : Solaris의 스레드 라이브러리(green threads), GNU Portable 스레드

일 - 대 - 일 모델
각 사용자 스레드를 각각 한 커널 스레드로 사상
한 스레드가 봉쇄적 SYS호출해도 타 스레도 실행 O => 병렬성 ^
장점 : 개발자가 원하는 만큼의 사용자 수준 스레드 생성 O
단점 : 사용자 수준 스레드 생성시 그에 따른 커널 스레드 생성해야 함 (오버헤드 의한 성능 감소)
한계 : 한 번에 한 스레드만이 커널 의해 스케줄됨 => 진정한 동시성은 X
예시 : Window95,98,2000,NT,XP,   Linux

다 - 다 - 다 모델
여러 사용자 수준 스레드를 그보다 작은 수/같은 수 커널 스레드로 멀티플렉스
필요만큼의 사용자 수준 스레드 생성 가능
    & 상응하는 커널스레드가 다중 처리기에서 병렬실행가능
스레드가 봉쇄형  sys호출 발생시키면, 커널 다른 스레드의 실행을 스케줄할 수 있음
변형 : 두 수준 모델
많은 사용자 스레드를 적거나 같은 수의 커널 스레드로 멀티플렉스 시키는 것 유지
	=> 한 사용자 스레드가 한 커널 스레드에 종속되도록 허용

4.3 스레드 라이브러리
스레드 라이브러리 : 스레드 생성, 관리 위한 API를 제공
구현방법
    1) 커널 지원 없이 완전히 사용자 공간에서만 라이브러리 제공
	- 라이브러리의 코드, 자료구조는 사용자 공간에 존재
	- 라이브러리 함수 호출은 시스템 호출이 아니라 사용자 공간의 지역함수를 호출하는 것
     2) OS 의해 지원되는 커널 수준 라이브러리 구현
	- 라이브러리 위한 코드, 자료구조는 커널 공간에 존재
	- 라이브러리 API 호출은 커널 시스템 호출과 동일
 라이브러리 종류
 	- POSIX Pthreads : 커널수준 lib
	- Win32 : 커널수준 lib
	- Java : 자바프로그램에서 직접 스레드 생성, 관리 가능
		  호스트 시스템에서 사용가능한 스레드 라이브러리 이용하여 구현

4.4 Java 스레드
Java 스레드 상태
자바 스레드는 한 가지 상태를 유지할 수 있다
새로운(New) : 명령어 이용해 스레드 객체 생성시 이 상태에 있게 됨
실행가능(runnable) : JVM에 의해 실행될 자격. 자바는 실행가능과 실행중을 구분X
봉쇄(blocked) : 봉쇄형 문장 실행(ex입출력) or 특정 자바스레드매서드 호출시
수명이 다 된(dead) : 스레드의 run( ) 매서드 끝났을 때







JVM과 호스트 운영체제
JVM은 하부OS 구현의 세세한 내용 감추고, JVM 지원하는 어떤 플랫폼에서도 자바 프로그램이 작동할 수 있는 일관되고 추상적인 환경 제공

생산자-소비자 문제에 대한 다중 스레드 해결책
메일 박스 생성
독립된 생산자와 소비자 스레드 생성
공유 메일 박스에 대한 참조를 각 스레드에게 전달
생산자 : 수면, item 생산, 메일박스에 item 넣기 번갈아 가며 실행
      소비자 : 수면, 메일박스로부터 item획득, item 소비 번갈아 가며 실행

4.5 스레드와 관련된 문제들
스레드 취소
스레드 취소 : 스레드가 끝나기 전에 강제 종료시키는 작첩
	ex) 여러 스레드가 db를 병렬로 검색하다가 결과를 찾았다면 나머지 스레드들은 취소!

목적 스레드(target thread) : 취소되어야 할 스레드
     1) 비동기식 취소 : 한 스레드가 목적 스레드를 즉시 강제 종료시킨다
	- 시스템 자원 전부를 사용 가능한 상태로 만들지 못할 수도
     2)지연 취소 : 목적 스레드가 주기적으로 자신이 강제 종료돼야 할지 점검
	- 실제 취소는 목적 스레드가 취소 여부 결정 위해 플래그 검사한 이후에야 일어남
	- 취소되어도 안전하다고 판단되는 시점에 취소 여부 검사

 interrupt() 메서드 통해 자바에서 지연 취소할 수 있음
     - 호출시 목적 스레드의 인터럽트 상태가 세트가 됨
     - 이 인터럽트 상태를 주기적으로 검사하는 건 목적스레드의 몫

신호처리
신호 : 어떤 사건이 일어났음을 알려주기 위해 사용
신호 전달 순서
    (1) 특정 사건이 일어나서 신호 생성
    (2) 프로세스에게 전달
    (3) 신호 전달시 반드시 처리되어야 함

종류
    1) 동기식 : 신호를 발생시킨 연산을 실행한 동일한 프로세스에게 전달
	ex) 불법적인 메모리 접근, 0으로 나누기
    2) 비동기식 : 실행 중인 프로세스 외부로 부터 신호가 발생

모든 신호는 처리기에 이해 처리
    1) 디폴트 신호 처리기
    2) 사용자 정의 신호 처리기 : 디폴트 신호 처리기를 대체 가능

신호 전달 방법
    1) 동기식 : 그 신호를 야기한 스레드에게 전달
    2) 비동기식 : 명확하지 않음 (모든 스레드에게 전달돼야 할 수도)

다중 스레드 UNIX : 스레드가 신호 전달/봉쇄할 수 있는 선택권을 줌
    - 신호는 오직 한 번만 처리돼야 함
	=> 신호를 받겠다고 선언한 스레드 중 첫 번째 스레드에게만 신호를 전달

Windows는 신호를 명시적으로 지원하진 않음
    - 비동기식 프로시저 호출(APC) 사용해 대리 실행 가능
    - UNIX와 차이점 : 특정 스레드에게 전달 됨

스레드 풀
다중 스레드 서버의 문제점
    1) 서비스시마다 스레드 생성하는데 소요되는 시간
    2) 동시에 실행될 수 있는 최대 스레드의 개수
스레드 풀 : 프로세스 시작시 일정 수 스레드를 미리 풀로 만들어 두는 것
스레드 풀 작동방식
    (1) 스레드 풀의 스레드들은 평소에는 일 없이 일감 기다림
    (2)  요청 들어오면 이 풀에서 한 스레드에게 요청 할당
    (3) 서비스 종료시 스레드는 다시 풀로 돌아가 다음 작업 기다림
    (4) 풀에 남아 있는 스레드가 바닥나면 서버는 자유 스레드 생성을 기다려야 함

장점
    - 새 스레드 생성보다 기존 스레드로 서비스하는게 빠름
    - 많은 수의 스레드를 병렬 처리할 수 없는 시스템에 도움

스레드별 데이터
한 프로세스에 속한 스레드들은 그 프로세스의 데이터를 모두 공유함
     => 상황에 따라 각 스레드가 자기만 접근할 수 있는 데이터 가져야 할 필요도 있음
	(스레드별데이터)

스케줄러 액티베이션
다-대-다 수준 모델에서 스레드 라이브러리와 커널의 통신 문제
   : 응용prog.가 최고 성능 보이게 보장하기 위해 커널 스레드 수를 동적으로 조정

중간 자료 구조(LWP 또는 경량프로세스) : 사용자와 커널 스레드 사이에 존재
    -  프로세스가 여러 LWP가 필요한데 일부만 가지고 있으면
       LWP가 커널에서 복귀할 때까지 대기

스케줄러 액티베이션 : 사용자 스레드 라이브러리와 커널 스레드 간 통신방법
    - 동작방법
	(1) 커널은 응용에게 LWP 집합을 제공
 	(2) 응용은 사용자 스레드를 가용한 가상 처리기로 스케줄
	(3) 커널은 응용에게 특정사건  대해 알려줌 (upcall)
	(4) 커널은 새로운 가상 처리기를 응용에게 할당
	(5) 응용은 새 가상 처리기 상에서 upcall 처리기 실행
	(6) upcall 처리기는 봉쇄 스레드 상태 저장하고 가상 처리기를 반환
	(7) upcall 처리기가 새 가상 처리기에서 실행 가능한 다른 스레드를 스케줄
	(8) 봉쇄 스레드가 기다리던 사건이 발생하면
	      커널은 봉쇄됐던 스레드가 실행가능한 것을 알리는 upcall을 스레드Lib.에 함
	(9) 커널은 새 가상 처리기 할당 or 사용자 스레드 선점해 upcall 처리기 실행
	(10) 응용은 봉쇄 풀린 스레드를 실행 가능 상태로 표시
	(11) 응용은 가상 처리기 상에서 다른 실행 가능한 스레드 실행

4.6 운영체제 사례
윈도우와 리눅스에서 스레드를 어떻게 구현하는가
Windows XP 스레드
응용들은 프로세스 형태로 실행되며 각 프로세스는 한 개 이상의 스레드 가질 수 있음
일-대-일 대응 사용하며 사용자 수준 스레드 하나마다 커널 스레드 하나가 대응됨

Linux 스레드
프로세스를 복제하는 fork() 시스템 호출을 제공
clone() : 스레드 생성할 수 있는 기능
리눅스에선 프로세스와 스레드를 구별하지 않음 (태스크라는 용어 사용)
fork() : 부모 프로세스의 해당 자료구조 복사함으로써 새 태스크 생성
clone() : 새 태스크 생성. 전달된 플래그에 따라 부모 태스크의 자료구조를 가리킴







챕터5 CPU 스케줄링
5.1 기본 개념
다중 프로그래밍의 목적 : 항상 어떤 프로세스를 실행하여 CPU이용률을 최대로 하는 것
프로세스가 대기할 경우 OS는 CPU를 그 프로세스로부터 회수해 다른 프로세스에 할당
CPU-입출력 버스트 사이클
프로세스 실행은 CPU실행과 입출력 대기의 사이클로 구성됨
프로세스는 CPU 버스트와 입출력 버스트를 교대로 왔다갔다함
    - 시작과 끝은 CPU버스트임

CPU 스케줄러
CPU가 유휴 상태될 때마다 OS는 준비완료 큐에 있는 프로세스 중 하나를 선택해 실행
스케줄러는 실행준비가 돼 있는 프로세스 중 하나를 선택해 CPU에 할당
큐에 있는 레코드는 일반적으로 PCB(프로세스 제어블록)임

선점 스케줄링
CPU스케줄링 결정은 네 가시 상황에서 발생할 수 있음
	1) 한프로세스가 실행상태에서 대기상태로 전환될 때
	2) 프로세스가 실행상태에서 준비완료 상태로 전환될 때
	3) 프로세스가 대기 상태에서 준비완료 상태로 전환될 때
	4) 프로세스가 종료할 때
  => 1), 4)의 경우 무조건 새로운 프로세스를 선택해야 함

비선점 스케줄링 : 상황 1),4)에서만 스케줄링이 발생
    - 일단 CPU가 한 프로세스에 할당되면 proc. 종료/대기 상태 전까지 CPU를 점유
선점 스케줄링 : 비선점 스케줄링이 아닌 것
    - 공유 자료 대한 접근 조정에 필요한 비용 발생 : 선점된 proc.가 공유데이터 읽을 경우
    - os 커널 설계에 영향
      : 커널이 프로세스 활동으로 커널 자료 변경 할 때 요청 프로세스가 선점되고 커널이
        동일 자료 구조 읽기/변경할 경우 혼란 발생
    - 인터럽트에 영향 받는 코드 부분은 동시 사용으로부터 보호되어야
      => 다수 proc.가 병행 접근 못하게 진입점에서 인터럽트 불능화/출구에서 가능화

디스패처
디스패처 : cpu 제러를 단기 스케줄러가 선택한 프로세스에 넘겨주는 모듈
작업
    - 문맥 교환
    - 사용자 모드로 전환
    - 프로그램 재시작위해 사용자 프로그램의 적절한 위치로 이동
모든 proc.의 문맥 교환시 호출됨
디스패치 지연 : 한 프로세스 정지시키고 타 프로세스 실행 시작까지 걸리는 시간

5.2 스케줄링 기준
cpu 이용률
처리량 : 단위시간당 완료된 프로세스의 개수
총처리 시간 : 프로세스의 제출 시간과 완료 시간의 간격
대기시간 : 스케줄링 알고리즘은 실행시간,입출력시간엔 영향x, 입출력큐대기시간에만 영향
응답시간 : 하나의 요청을 제출한 후 첫 응답이 나올때까지의 시간 (응답시작까지걸리는시간)

대화식 시스템에서는 평균응답시간의 최소화보다 응답시간의 변동폭 최소화가 중요

5.3 스케줄링 알고리즘
CPU스케줄링 : 준비완료 큐에 있는 어느 프로세스에게 cpu를 할당할지 결정

선입 선처리 스케줄링 (FCFS ; First-Come, First-Served)
먼저 요청하는 프로세스가 cpu를 먼저 할당받음
선입선출 큐로 관리
cpu가 자유시간이 되면 준비완료 큐 앞부분에 있는 프로세스에게 할당되고, 해당 프로세스는 제거
선점 스케줄링임
호위효과 : 모든 다른 프로세스들이 하나의 긴 프로세스가 cpu를 양도하기를 기다리는 것
    - 하나의 cpu 중심 프로세스와 많은 입출력 프로세스가 있는 상황에서.
단점 : 평균 대기시간이 길어질 수 있음, 시분할 시스템에는 부적합

최단 작업 우선 스케줄링 (SJF ; Shortest-Job-Fisrt)
Cpu 버스트가 가장 작은 프로세스에게 할당
평균 대기시간 감소
장기 스케줄링에서 자주 사용
한계 : 현실적으로 cpu요청의 길이를 파악하는 것은 어려움
	=> 단기 스케줄링에서는 구현 어려움 : 다음 cpu버스트 알 수 없어서.
	=> 다음 cpu 버스트 길이를 예측해서 구현할 수는 있음
cpu 버스트 길이 예측
    - 이전 cpu 버스트들의 길이를 지수 평균한 것.
    - 최근값과 이전값의 상대적 가중치를 조절
	- 가중치=0 : 최근 실행은 아무 영향 미치지 않음
	  가중치=1 : 오직 가장 최근의 cpu버스트만 중요시 됨
	  가중치=1/2 : 최근의 실행과 과거의 실행추이가 같은 가중치 가지게 됨
선점형 또는 비선점형 둘 다 가능
    -  선점형 SJF는 도착시간이 빠른 게 먼저 실행되나, 현재 실행되는 프로세스의 잔여시간보다
       대기 중인 프로세스의 버스트가 더 작으면 이 프로세스가 선점함.















우선순위 스케줄링 (Priority Scheduling)
SJF 스케줄링의 응용
가장 높은 우선순위 가진 프로세스에게 cpu 할당
우선순위(p)는 cpu 버스트가 작을수록 높음
    - 우선순위가 같을 경우 선입선처리(FCFS)로 스케줄
 선점형 또는 비선점형 가능
    - 선점형 : 새로 도착한 프로세스의 우선순위가 현재 실행되는 프로세스의 우선순위보다
		높으면 선점
    - 비선점형 : 단순히 준비완료 큐의 머리 부분에 새로운 프로세스를 넣음
문제점
    - 무한봉쇄(기아상태) : 낮은 우선순위 프로세스들이 cpu를 무한정 대기
    - 해결책 : 노화
	=> 오랫동안 sys에서 대기하는 프로세스들의 우선순위를 점진적으로 증가시키는 기법

라운드 로빈 스케줄링 (RR)
시분할 sys 위해 설계
FCFS와 유사하지만 선점이 추가됨
시간할당량(시간 조각)이라 하는 작은 단위의 시간을 정의
준비완료 큐는 원형 큐로 동작
cpu 스케줄러는 준비완료 큐를 돌면서 한 번에 한 프로세스에게
    한 번의 시간 할당량 동안 cpu 할당
구현
    - 준비완료 큐는 선입선출 큐임
    - 새 프로세스들은 큐의 꼬리에 추가됨
    - cpu 스케줄러는 큐에서 첫 프로세스를 선택해 한 번의 시간 할당량 이후
      인터럽트 걸도록 타이머 설정 후 프로세스를 디스패치

시나리오
    1) 프로세스의 cpu 버스트 < 시간 할당량
        - 프로세스 자신이 cpu를 자발적으로 방출
        - 준비완료 큐에 있는 다음 프로세스가 실행
    2) cpu 버스트 > 시간 할당량
        - 타이머가 끝나면 os에게 인터럽트 전달
       - 문맥교환
       - 실행중이던 프로세스는 준비완료 큐의 꼬리에 넣어짐

평균 대기시간이 길어지는 경우가 많음
 각 프로세스는 (n-1)xq 시간 이상을 대기 하지는 않음 (n:프로세스개수, q:시간할당량)
q가 너무 크면 FCFS와 똑같아짐
q가 너무 작으면 문맥교환 시간 때문에 프로세스 실행이 느려짐
평균 총처리 시간은 시간 할당량 크기가 증가하더라도 반드시 개선되지는 않음

다단계 큐 스케줄링
프로세스의 구분
 	- 포그라운드(대화형) 프로세스
	- 백그라운드(일괄처리) 프로세스
  => 포그라운드 프로세스는 백그라운드보다 높은 우선순위 가질 수 있음

다단계 큐 스케줄링 구현
	(1) 준비완료 큐를 여러 별도 큐로 분류
	(2) 각 큐는 자신만의 스케줄링 알고리즘을 가지고 있음
	(3) 프로세스들을 특성에 따라 한 개의 큐에 영구적으로 할당

큐와 큐 사이의 스케줄링도 필요
	=> 일반적으론 고정 우선순위의 선점형 스케줄링으로
    - 큐 사이엔 우선순위가 존재
    - 각 큐는 낮은 우선순위의 큐보다 절대적인 우선순위를 가짐

장점 : 오버헤드가 적음 (영구적으로 하나의 큐에만 할당되니까)
단점 : 융통성이 적음

다단계 피드백 큐 스케줄링
프로세스가 큐 사이를 이동하는 것을 허용
여러 매개변수에 의해 정의됨
	ex) 큐의 개수, 각 큐를 위한 스케줄링 알고리즘 등
장점 : 상황에 맞는 최선의 스케줄러가 될 수 있음
단점 : 가장 복잡한 알고리즘임 (설계시 모든 매개변수들의 값을 선정해야 함)

5.4 다중처리기 스케줄링
이 전까지는 단일처리기 시스템에서의 스케줄링을 다뤘다. 다중처리기 시스템에선 여러 개의 CPU가 사용가능함.

다중처리기 스케줄링 접근방법
비대칭 다중처리
주 서버라는 하나의 처리기가 모든 스케줄링 결정, 입출력 처리, 타 시스템 활동을 처리
자료 공유할 필요가 감소 => 구현 간단

2) 대칭 다중처리(SMP ; symmetric multiprocessing)
각 처리기가 독자적으로 스케줄링
두 처리기가 같은 프로세스 선택하지 않고 프로세스들이 큐에서 사라지지 않는 다는 것을 보장해야 => 구현 복잡

처리기 친화성
처리기 친화성 : 프로세스가 현재 실행 중인 처리기에 친화성을 가진다는 것
	(1) 프로세스가 특정 처리기에서 실행 중일때,
	  처리기가 가장 최근에 접근한 데이터가 캐시를 채움
	(2) 프로세스가 다른 처리기로 이주하면
	  원래 처리기의 캐시 내용은 무효화 돼야 함 & 현 처리기 캐시는 다시 채워져야
	(3) 캐시 무효화하고 다시 채우는 건 비용이 많이 듦
		=> SMP 시스템은 한 처리기에서 다른 처리기로의 이주를 피함

유형
	1) 약한 친화성 : os가 동일 처리기에서 프로세스 실행시키려 노력하는 정책 가지고 있지만
						  보장하진 않음 (이주가 가능)
	2) 강한 친화성 : 프로세스가 다른 처리기로 이주하지 않는 프로세스를 지정 가능
						   ex) 리눅스

부하 균등화
부하 균등화 : 모든 처리기 사이에 부하가 고르게 배분되도록 시도
	- 단, 전용 큐를 가진 시스템에서만 필요한 기능임
	   (전용 큐 : 각 처리기가 실행할 프로세스를 선택할 수 있는 자신만의 큐)
	- 공용 실행큐만 있는 시스템에선 한 처리기가 쉬게 되면 곧바로 공용 큐에서 새 프로세스 선택
		=> 부하균등화 필요 x

부하 균등화의 방식
	1) push 이주
		- 특정 태스크가 주기적으로 각 처리기의 부하를 검사
		- 불균등 상태로 밝혀지면 과부하인 처리기에서 안 바쁜 다른 처리기로 프로세스 이동
	2) pull 이주
		- 쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 pull
=> push와 pull은 상호 배타적일 필요는 없음. 가끔 병렬적으로 구현되기도

부하 균등화는 처리기 친화성 이득에 상충함
	- 처리기 친화성 이점 : 프로세스가 그 처리기의 캐시에 존재하는 데이터를 활용하는 것
	- 부하 균등화는 프로세스를 다른 처리기로 pull/push함으로써 이 이점을 무효화시킴

대칭적 다중 스레딩
대칭적 다중 스레딩(SMT ; symmetric multithreading)
	- SMP는 다수의 물리 처리기를 제공
	- SMT는 다수의 논리 처리기 제공

각 처리기는 자신의 구조 상태를 갖게 됨
인터럽트 처리 대한 책임도 논리 처리기에게
논리 처리기는 캐시 메모리와 버스 같은 물리 처리기의 자원을 공유ㅠ함

SMT는 s/w가 아닌 h/w가 제공하는 특성임
	=> 즉, h/w는 인터럽트 처리뿐 아니라 각 논리 처리기 구조 상태를 나타낼 수 있어야

5.5 스레드 스케줄링
os에서 스케줄되는 대상은 프로세스가 아닌 커널 수준 스레드.
사용자 수준 스레드는 스레드 lib.에 의해 관리되고, 커널은 그 존재를 알지 못함.
cpu상에서 실행되기 위해서 사용자 수준 스레드는 연관된 커널 수준 스레드에 사상돼야 함

경쟁 범위
프로세스-경쟁-범위(PCS ; Process-Contention Scope)
다-대-일, 다-대-다 sys 상에서 스레드 lib.는 사용자 수준 스레드를 가용한 LWP상에서 스케줄
2) 시스템-경쟁범위(SCS ; System-Contention Scope)
SCS스케줄링에서 CPU대한 경쟁은 sys상의 모든 스레드 사이에서 일어남

5.6 운영체제 사례들
Solaris 스케줄링
우선순위 기반 스레드 스케줄링
디폴트로 시분할 스케줄링 사용
고정 우선순위, 공평 공유라는 새로운 두 스케줄링 클래스 도입함
낮은 우선순위 태스크에게 더 긴 시간 할당량 배정

 Windows XP 스케줄링
우선순위에 기반을 둔 선점 스케줄링 알고리즘
디스패처 : Windows xp의 커널 중 스케줄링을 담당하는 부분
각 스레드의 우선순위는 스레드가 속한 우선순위 클래스와 그 클래스 안에서의 상대적인 우선순위에 기반을 둠
스레드의 시간 할당량 만료시 인터럽트됨
	- 스레드가 가변 우선순위 클래스에 속한다면 우선순위 낮아짐
		=> 계산 중심 스레드들이 cpu 사용하는 것을 제한. 대화형 스레드들에게 빠른 응답시간
낮은 우선순위 태스크에게 더 긴 시간 할당량 배정

Linux 스케줄링
Sys 상의 태스크 개수와 상관없이 항상 상수 시간에 실행
SMP를 위한 향상된 지원 제공
개별적인 두 개의 우선순위 영역을 갖는 선점형, 우선순위 기반 알고리즘 사용
	- 실시간 영역 : 0~99까지의 우선순위, nice 영역 : 100~140까지 우선순위
높은 우선순위 태스크에게 더 긴 시간 할당량 배정(Solaris, Windows와의 차이점)
커널은 실행 가능한 태스크들의 리스트를 runqueue 자료구조에 유지
runqueue는 active와 expired라는 두 우선수누이 배열을 가짐
	- active : 시간 조각이 남아 있는 모든 태스크를 포함
	- expired : 모든 만료된 태스크

5.7 Java 스케줄링 (책 다시읽기!)
낮은 우선순위의 스레드가 높은 우선순위 스레드보다 먼저 실행될 기회 얻을 수도
협력적 다중태스킹 : 스레드는 yield()메서드 이용해 cpu의 제어를 양보할 수도 있음

스레드 우선순위
JVM은 동적으로 우선순위를 변경하지 않음
	=> 스레드는 생성될 때 가진 디폴트 우선순위를 생존기간 동안 유지

5.8 알고리즘의 평가
결정론적 모델링
분석적 평가 : 작업부하에 대한 알고리즘의 성능을 평가하는 공식이나 값을 구한다.
결정론적 모델링 : 분석적 평가의 한 유형으로 사전에 정의된 특정한 작업 부하에 대한
							각 알고리즘의 성능을 정의한다.
	- 장점 : 비교할 수 있도록 정확한 값을 제공
	- 단점 : 입력으로 정확한 숫자 요구. 응답도 단지 주어진 입력의 경우에만 적용
	=> 프로그램의 처리 요구사항들을 정확하게 측정할 수 있는 경우에 좋음

큐잉 모델
현실적으로 프로세스들은 날마다 변화하기때문에 결정론적 모델링을 사용할 수 있는
	프로세스의 정적인 집합은 없음
단, cpu와 입출력 버스트의 분포는 결정 가능
	=> 도착률과 서비스율을 알 수 있음 => 이용률, 평균 큐 길이, 평균 대기시간 계산 가능








				<Little’s formula> : W의 시간 동안 ㅅ x W의 프로세스들이 큐에 도착함
한계 : 현재 분석할 수 있는 알고리즘과 분포 부류가 상당히 제한됨
			결과의 정확성에는 의심의 여지가 있음

모의실험
모의실험 : 컴퓨터 시스템의 모델을 프로그래밍 하는 것
실험 통해 알고리즘 성능 나타내는 통계를 수집
한계 : 실제 시스템에서 연속적인 사건들 사이의 관계 때문에 부정확할 수 있음
추적 테이프 : 실제 시스템을 관찰해 실제 사건들의 순서 기록
	=> 입력 대한 정확한 결과 생성

구현
실제 코드로 작성해 os에 넣고 실행해 보는 것
한계 : 높은 비용, 알고리즘 사용 환경의 계속된 변화


5.9 연습문제
입출력 중심 프로그램은 적은 연산을 수행한다. 따라서 CPU 할당량을 많이 사용하지 않는다.
	 CPU 중심 프로그램은 할당량 전체를 사용한다. 결과적으로 입출력 중심 p에게 우선권을 줌으
	 로써 컴퓨터 자원을 절약할 수 있다.
2.
CPU 이용률은 문맥교환과 관련한 오버헤드가 최소화될 경우 증가한다. 문맥교환 오버헤드는 문맥교환의 빈도를 낮춤으로써 줄일 수 있다. 하지만 이는 응답시간의 증가를 불러온다
평균 총처리 시간은 가장 짧은 태스크를 처음에 실행함으로써 줄일 수 있다. 그러나 이러한 방식은 긴 태스크가 실행되지 못하게 하며 결국 대기시간을 증가시킨다
cpu이용률은 문맥교환없이 cpu중심의 긴 태스크를 실행할 때 극대화된다. 입출력장치 이용률은 입출력 중심 태스크를 최대한 빨리 준비되게 할 때 극대화된다. 이때, 문맥교환의 오버헤드가 발생한다.
5. 최소작업우선
6.
	a) 프로세스의 우선순위는 높아진다. 더 빈번하게 할 수록 선호도를 많이 받기 때문
	b) 이점은 가장 중요한 일에 더 시간을 할애할 수 있다. 하지만 짧은 태스크는 기다려야 한다.
	c) 높은 우선순위 프로세스에 더 많은 시간을 할당한다.
7.
	b) 입출력중심 태스크는 1msec마다 문맥교환을 함
		총 시간은 10*1.1 +10.1
		cpu 이용률은 20/21.1*100=94%

	* cpu 이용률 = (시스템시간-유휴시간)/시스템시간

8. 시간 할당량을 완전히 사용하지 않음으로써 가능. 즉, 시간할당량을 큰 조각으로 사용하되, 시간할당량 이전에 cpu를 놔준다. 결국 프로세스의 우선순위를 높일 수 있다.

9. a) FCFS b) LIFO
10.
a) 늦게 도착한 짧은 프로세스는 차별받음
b) 모든 태스크를 평등하게. 따라서 짧을 수록 결론적으론 더 빨리 처리됨
c) RR과 유사 - 짧을수록 선호



















챕터6 프로세스 동기화
협력적 프로세스란? : 시스템 내에서 실행 중인 타 프로세스 실행에 영향 주거나 받는 프로세스
=> 논리주소 공간을 공유하는 협력적 프로세스의 질서 있는 실행을 보장하여
‘데이터의 일관성’을 유지하는 다양한 메커니즘을 논의한다.

6.1 배경
생산자-소비자 문제
	- 생산자와 소비자 코드를 병행하게 실행시키면 올바르게 동작하지 않는다.
	- 공유 메모리에 동시에 접근할 수 있기 때문
경쟁 조건
	- 동시에 여러 프로세스가 동일 자료에 접근하여 조작하고,
	  그 실행 결과가 접근이 발생한 특정 순서에 의존하는 상황

=> 경쟁조건으로부터 보호하기 위해선
	한 순간에 하나의 프로세스만이 변수를 조작하도록 보장해야 함
	(프로세스 동기화의 필요성)

6.2 임계영역 문제
임계영역
	- 각 프로세스는 임계역영이라고 부르는 코드 부분을 포함하고 있다
	- 임계영역에서는 다른 프로세스와 공유하는 변수를 변경/테이블 갱신/파일 쓰기 등의 작업을
	   수행
	- 한 프로세스가 자신의 임계영역에서 실행하는 동안 타 프로세스들은 그 임계영역에 들어갈  
	  수 없음

임계영역 문제
	- 프로세스들이 협력할 때 사용할 수 있는 프로토콜을 설계한다
	- 각 프로세스는 자신의 임계영역으로 진입할 때 진입허가를 요청

임계영역 문제의 해결안의 세 가지 요구조건
1) 상호배제 : 프로세스 Pi가 자기의 임계영역에서 실행된다면, 다른 프로세스는 그들 자신의 임계영역	에서 실행될 수 없다.
2) 진행 : 자기의 임계영역에서 실행 중인 프로세스가 없고, 자신의 임계영역으로 진입하려고 하는 프로세스들이 있다면, 나머지 영역에서 실행 중이지 않은 프로세스들만 임계영역으로 진입할 프로세스를 결정하는데 참여할 수 있으며, 이 선택은 무한정 연기될 수 없다.
3) 한정된 대기 : 프로세스가 자기 임계영역에 진입하려는 요청을 한 후부터 그 요청이 허용될 때까지 다른 프로세스들이 그들 자신의 임계영역에 진입할 수 있는 횟수에는 제한이 있어야 함

임계영역을 다루는 접근법
선점형 커널
	- 실시간 프로그래밍에 적당 (실시간으로 프로세스가 선점할 수 있기 때문)
	- 더 신속하게 응답 가능
비선점형 커널 : 경쟁 조건을 염려할 필요 x (실행중인 프로세스가 하나 밖에 없기 때문)
5.3 피터슨의 해결안
한계 : 현대 컴퓨터 구조가 기본적인 기계어를 실행하는 방식이라 이 해결안이 올바르게 실행된다는 보장은 없음
피터슨의 해결안
	- 가정 : 임계영역과 나머지 영역을 번갈아 가며 실행하는 두 개의 프로세스로 한정된다.
		(Pi와 Pj. 단, j=1-i)
	- 두 프로세스가 공유하는 두 데이터 항목
		1) 변수 turn : 임계영역으로 진입할 순번
		2) flag 배열 : 프로세스가 임계영역으로 진입할 준비가 되었음을 나타냄
임계영역 진입방법
	- Pi가 flag[i]를 참으로 만들고, turn을 j로 지정
	- 만일 두 프로세스가 동시에 진입하기를 원한다면 : turn은 동시에 i와 j로 지정됨
		=> 그러나 둘 중 오직 한 배정만이 지속됨
		=> 즉, turn의 궁극적인 값이 둘 중 누가 먼저 임계영역으로 진입할 것인지 결정

증명
while (true) {
	flag[i] = TRUE;
	turn = j;
	while (flag[j] && turn == j);
	임계영역
	flag[i] = FALSE;
	나머지영역
}
<피터슨 해결안에서 Pi 구조>

증명할 거리
상호배제가 제대로 지켜진다
=> turn의 값은 0또는1의 값을 가짐. 동시에 두 값을 가질 순 없음. 따라서 한 프로세스만이 while을 통과할 수 있음
진행에 대한 요구 조건을 만족한다는 사실
대기시간이 한없이 길어지지 않는다는 사실
=> 임계영역을 빠져나올 때 flag를 false로 재지정
=> 지난번에 다른 프로세스에 진입했다면 이번엔 자기도 한 번은 들어갈 수 있게 보장


6.4 동기화 하드웨어
임계영역에 대한 임의의 해결책은 록(lcok)이란 간단한 도구가 필요
	=> 경쟁조건은 임계영역이 록에 의해 보호함으로써 예방 가능

단일처리기 환경에서의 임계영역문제
	- 공유 변수가 변경되는 동안 인터럽트 발생을 비허용해서 해결
		=> 명령어의 현재 순서가 선점되지 않고 순차적으로 실행됨
		=> 다른 명령어가 실행될 수 없음
	- 한계 : 다중처리기 환경에서는 적용 불가
		=> 모든 프로세서에게 인터럽트 불능화 메시지를 보내야 하기 때문
		=> 시스템 효율 떨어짐

다중처리기 환경에서의 임계영역문제
	- 한 워드(word)의 내용 검사하고 변경하거나 두 워드 내용을 원자적으로 swap할 수 있는,
	   즉 인터럽트 되지 않는 하나의 단위로서 특별한 하드웨어 명령어들을 제공한다.

6.5 세마포
세마포 : 임계영역 문제를 위한 동기화 도구
한 스레드가 세마포 값을 변경하면 다른 어떤 스레드도 동시에 동일한 세마포 값을 변경할 수 없음

사용법
세마포 종류
	1) 계수 세마포 : 영역에 제한 x
	2) 이진 세마포 : 0과 1사이의 값만 가능 (상호배제를 제공)
	=> 프로세스/스레드들이 임계영역 접근하는 걸 제어하기 위해 이진 세마포 사용 가능

